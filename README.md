# counter-deploy
Пример проекта для деплоя приложения счетчик на сервер

## Развертывание с 4 репликами Flask приложения

### Конфигурация Docker Swarm

Файл `docker-compose.swarm.yml` содержит конфигурацию для кластеризованного развертывания:

- 4 реплики Flask приложения
- Встроенная балансировка нагрузки

### Команды для развертывания

```bash
# Инициализация Swarm (если еще не инициализирован)
docker swarm init

# Сборка образа
docker build -t localhost:5000/counter-app:latest .

# Развертывание стека
docker stack deploy -c docker-compose.swarm.yml counter

# Проверка статуса сервисов
docker stack services counter

# Просмотр реплик
docker service ps counter_app
docker service ps counter_redis

# Масштабирование сервиса (изменить количество реплик без редактирования файла)
docker service scale counter_app=1  # Уменьшить до 1 реплики
docker service scale counter_app=4  # Увеличить до 4 реплик
```

### Остановка и удаление стека

```bash
# Удаление стека (остановит все сервисы и удалит стек)
docker stack rm counter

# Ожидание полного удаления стека (проверка статуса)
docker stack services counter

# Удаление неиспользуемых сетей
docker network prune -f

# Полная остановка Swarm (после удаления всех стеков)
docker swarm leave --force
```

**Примечание:** Если порт 80 уже занят другим стеком, необходимо сначала удалить предыдущий стек командой `docker stack rm <имя_стека>`.
```

### Доступ к приложению

После успешного развертывания приложение будет доступно по адресу:

- **http://localhost**

Приложение использует порт **80** для внешнего доступа. Балансировщик нагрузки Docker Swarm автоматически распределяет запросы между 4 репликами Flask приложения.

## Развертывание с реплицированной БД (Redis)

### Конфигурация с несколькими репликами Redis

Файл `docker-compose.swarm-replicated.yml` содержит конфигурацию с **3 репликами Redis** для повышения отказоустойчивости.

### Особенности работы с реплицированной БД

**Важно:** При использовании нескольких реплик Redis в Docker Swarm с настройкой по умолчанию возникают следующие особенности:

1. **Независимые экземпляры БД**
   - Каждая реплика Redis является независимым экземпляром
   - Данные **не синхронизируются** автоматически между репликами
   - Каждое подключение может попасть на любой экземпляр Redis

2. **Проблема консистентности данных**
   - Запись в одну реплику не отражается в других
   - Разные экземпляры приложения могут видеть разные данные
   - Потеря целостности данных счетчика

3. **Балансировка подключений**
   - Docker Swarm распределяет подключения между репликами случайным образом
   - Нет контроля, какое приложение к какой реплике подключается

### Пути решения проблем репликации

Для корректной работы с несколькими репликами Redis необходимо выбрать один из подходов:

1. **Redis Sentinel**
   - Автоматическое управление master и replicas
   - Автоматический failover при отказе master
   - Требует дополнительной настройки конфигурации

2. **Redis Cluster**
   - Распределение данных по нескольким узлам
   - Автоматическая репликация
   - Более сложная настройка, но лучшая производительность

3. **Внешний managed Redis** (AWS ElastiCache, Redis Cloud и т.д.)
   - Управляемый сервис с автоматической репликацией
   - Минимальная настройка, максимальная надежность

**Примечание:** Текущая конфигурация `docker-compose.swarm-replicated.yml` демонстрирует развертывание нескольких реплик, но без синхронизации данных.

### Команды для развертывания с реплицированной БД

```bash
# Инициализация Swarm (если еще не инициализирован)
docker swarm init

# Сборка образа
docker build -t localhost:5000/counter-app:latest .

# Развертывание стека с реплицированной БД

docker stack deploy -c docker-compose.swarm-replicated.yml counter-replicated

# Проверка статуса сервисов
docker stack services counter-replicated

# Просмотр реплик
docker service ps counter-replicated_app
docker service ps counter-replicated_redis
```

### Остановка и удаление стека

```bash
# Удаление стека (остановит все сервисы и удалит стек)
docker stack rm counter-replicated

# Ожидание полного удаления стека (проверка статуса)
docker stack services counter-replicated

# Удаление неиспользуемых сетей (опционально)
docker network prune -f

# Полная остановка Swarm (после удаления всех стеков)
docker swarm leave --force
```

**Примечание:** Если порт 80 уже занят другим стеком, необходимо сначала удалить предыдущий стек командой `docker stack rm <имя_стека>`.

## Нагрузочное тестирование

Для проверки производительности приложения с 4 репликами используется Locust.

### Установка Locust

Рекомендуется использовать виртуальное окружение для избежания конфликтов зависимостей:

```bash
# Создание виртуального окружения
python3 -m venv venv

# Активация виртуального окружения
source venv/bin/activate

# Установка Locust
pip install locust
```

Для деактивации виртуального окружения используйте:
```bash
deactivate
```

### Запуск нагрузочного тестирования

После активации виртуального окружения:

```bash
# Запуск Locust с веб-интерфейсом (по умолчанию http://localhost:8089)
locust --host=http://localhost

# Запуск без веб-интерфейса (headless режим) для автоматизированного тестирования
locust --host=http://localhost --headless -u 300 -r 30 -t 60s

# Где:
# -u 300 - 300 пользователей (виртуальных клиентов)
# -r 30  - скорость набора пользователей (30 в секунду)
# -t 60s - длительность теста (60 секунд)
```

### Веб-интерфейс Locust

После запуска `locust --host=http://localhost` откройте в браузере:

- **http://localhost:8089**

В веб-интерфейсе можно:
- Указать количество пользователей
- Указать скорость набора пользователей
- Запустить тест и наблюдать статистику в реальном времени
- Экспортировать отчеты

### Сравнение производительности

Для сравнения производительности можно использовать команду масштабирования:

**Тест с 1 репликой**

```bash
docker service scale counter_app=1
locust --host=http://localhost --headless -u 300 -r 30 -t 60s
```

**Тест с 4 репликами**

```bash
docker service scale counter_app=4
locust --host=http://localhost --headless -u 300 -r 30 -t 60s
```